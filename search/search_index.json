{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Your Wiki to implement Awesome Applications with Astra Welcome to the Awesome Astra wiki! As the name stated it is an attempt to gather all information regarding Astra usage in a single place to help you in the development of your applications. It is a community and collaborative effort, if you have some inputs or correction please do so. \ud83d\udee0\ufe0f Coding with Astra \ud83d\udce6 Using Astra with - **[Apache Airflow](https://github.com/datastaxdevs/awesome-astra/wiki/Using-Airflow-with-Astra)**: Apache Airflow is an open source workflow management system. It provides components which allow engineers to build data pipelines between different systems - **[Apache Nifi](https://github.com/datastaxdevs/awesome-astra/wiki/Using-Apache-Nifi-with-Astra)**: NiFi was built to automate the flow of data between systems. While the term 'dataflow' is used in a variety of contexts, we use it here to mean the automated and managed flow of information between systems. - **[Apache Spark](https://github.com/datastaxdevs/awesome-astra/wiki/Apache-Spark-Integration):** Apache Spark is an open-source, distributed processing system used for big data workloads. It utilizes in-memory caching, and optimized query execution for fast analytic queries against data of any size. Use Apache Spark to connect to your database and begin accessing your Astra DB tables using Scala in spark-shell. - **[Cloud Functions (Python Driver)](https://github.com/datastaxdevs/awesome-astra/wiki/Cloud-Functions-(Python-Driver))**: Google's function-as-a-service offering that provides a serverless execution environment for your code. Cloud Functions are commonly used to extend Astra DB with additional data processing capabilities and connect Astra DB with other cloud services into data pipelines. - **[Cloud Functions (Python SDK)](https://github.com/datastaxdevs/awesome-astra/wiki/Cloud-Functions-(Python-SDK))**: Google's function-as-a-service offering that provides a serverless execution environment for your code. Cloud Functions are commonly used to extend Astra DB with additional data processing capabilities and connect Astra DB with other cloud services into data pipelines. - **[Cql Proxy](https://github.com/datastaxdevs/awesome-astra/wiki/CQL-Proxy)**: cql-proxy is designed to forward your application's CQL traffic to an appropriate database service. It listens on a local address and securely forwards that traffic. - **[Cql Shell](https://github.com/datastaxdevs/awesome-astra/wiki/Cql-Shell)**: the standalone CQLSH client is a separate, lightweight tool you can use to interact with your database. - **[Datagrip Jetbrains](https://github.com/datastaxdevs/awesome-astra/wiki/Using-Datagrip-With-Astra):** DataGrip is a database management environment for developers. It is designed to query, create, and manage databases. Databases can work locally, on a server, or in the cloud. Supports MySQL, PostgreSQL, Microsoft SQL Server, Oracle, and more. If you have a JDBC driver, add it to DataGrip, connect to your DBMS, and start working. - **[DataStax Bulk](https://github.com/datastaxdevs/awesome-astra/wiki/Using-DSBulk-with-Astra):** The DataStax Bulk Loader tool (DSBulk) is a unified tool for loading into and unloading from Cassandra-compatible storage engines, such as OSS Apache Cassandra\u00ae, DataStax Astra and DataStax Enterprise (DSE). - **[DBeaver](https://github.com/datastaxdevs/awesome-astra/wiki/DBeaver)**: DBeaver is a universal database management tool for everyone who needs to work with data in a professional way. With DBeaver you are able to manipulate with your data like in a regular spreadsheet, create analytical reports based on records from different data storages, export information in an appropriate format. - **[IntelliJ IDEA](https://github.com/datastaxdevs/awesome-astra/wiki/IDE-Intellij-Plugin)**: The Capable & Ergonomic Java IDE by JetBrains - **[JanusGraph](https://github.com/datastaxdevs/awesome-astra/wiki/JanusGraph):** JanusGraph is designed to support the processing of graphs so large that they require storage and computational capacities beyond what a single machine can provide. Scaling graph data processing for real time traversals and analytical queries is JanusGraph\u2019s foundational benefit. This section will discuss the various specific benefits of JanusGraph and its underlying, supported persistence solutions. - **[Micronaut](https://github.com/datastaxdevs/awesome-astra/wiki/Framework-Micronaut)**: Micronaut is a modern, JVM-based, full stack Java framework designed for building modular, easily testable JVM applications with support for Java, Kotlin, and Groovy. Micronaut is developed by the creators of the Grails framework and takes inspiration from lessons learnt over the years building real-world applications from monoliths to microservices using Spring, Spring Boot and Grails. - **[MindDB](https://github.com/datastaxdevs/awesome-astra/wiki/Using-MindDB-with-Astra)**:MindsDB enables you to use ML predictions in your database using SQL. - **[Pentaho Data Integration](https://github.com/datastaxdevs/awesome-astra/wiki/Pentaho-Data-Integration)**: Pentaho Data Integration (PDI) provides the Extract, Transform, and Load (ETL) capabilities that facilitate the process of capturing, cleansing, and storing data using a uniform and consistent format that is accessible and relevant to end users and IoT technologies. - **[TablePlus](https://github.com/datastaxdevs/awesome-astra/wiki/TablePlus):** TablePlus is a modern, native tool with elegant UI that allows you to simultaneously manage multiple databases such as MySQL, PostgreSQL, SQLite, Microsoft SQL Server and more.","title":"\ud83c\udfe0 Home"},{"location":"create-instance/","text":"\ud83c\udfe0 Back to home | Written by **Cedrick Lunven* , Last Update 2/10/2022 * Reference documentation A - Overview \u00b6 ASTRA DB is the simplest way to run Cassandra with zero operations at all - just push the button and get your cluster. No credit card required, $25.00 USD credit every month, roughly 5M writes, 30M reads, 40GB storage monthly - sufficient to run small production workloads. B - Prerequisites \u00b6 You should have an Astra account . If you don't have one yet, keep reading and we'll show you how to create it. C - Procedure \u00b6 \u2705 Step 1:Click the sign-in button to login or register. \u00b6 You can use your Github , Google accounts or register with an email . With the latest make sure to chose a password with minimum 8 characters, containing upper and lowercase letters, at least one number and special character. If you already have an Astra account, skip this step, locate and click the \"Create Database\" button on the left-side navigation bar of your Astra UI, and read next step. \u2705 Step 2: Complete the creation form \u00b6 As you create a new account, you will be prompted to create a database; you will see the same form if you simply hit the \"Create database\" button in your existing Astra account. \u2139\ufe0f Fields Description Field Description database name It does not need to be unique and not used to initialize a connection but only a label (Between 2 and 50 characters). It is recommended to have a database for each of your application. The free tier is limited to 5 databases. keyspace It is a logical grouping of your tables. (Between 2 and 48 characters), Please use lower cases and snake_case . Cloud Provider Use the one you like, click a cloud provider logo, pick an Area in the list and finally pick a region. We recommend to pick one the closes to you to readuce latencies but in free tier very few difference. \u2139\ufe0f Create Database button becomes enabled only when all fields are filled properly. Please use only lower cases and no space for a keyspace name. \u2139\ufe0f You will see your new database pending in the Dashboard.The status will change to Active when the database is ready, this will only take 2-3 minutes. You will also receive an email when it is ready. \ud83d\udc41\ufe0f Walkthrough","title":"Temporal"},{"location":"create-instance/#a-overview","text":"ASTRA DB is the simplest way to run Cassandra with zero operations at all - just push the button and get your cluster. No credit card required, $25.00 USD credit every month, roughly 5M writes, 30M reads, 40GB storage monthly - sufficient to run small production workloads.","title":"A - Overview"},{"location":"create-instance/#b-prerequisites","text":"You should have an Astra account . If you don't have one yet, keep reading and we'll show you how to create it.","title":"B - Prerequisites"},{"location":"create-instance/#c-procedure","text":"","title":"C - Procedure"},{"location":"create-instance/#step-1click-the-sign-in-button-to-login-or-register","text":"You can use your Github , Google accounts or register with an email . With the latest make sure to chose a password with minimum 8 characters, containing upper and lowercase letters, at least one number and special character. If you already have an Astra account, skip this step, locate and click the \"Create Database\" button on the left-side navigation bar of your Astra UI, and read next step.","title":"\u2705 Step 1:Click the sign-in button to login or register."},{"location":"create-instance/#step-2-complete-the-creation-form","text":"As you create a new account, you will be prompted to create a database; you will see the same form if you simply hit the \"Create database\" button in your existing Astra account. \u2139\ufe0f Fields Description Field Description database name It does not need to be unique and not used to initialize a connection but only a label (Between 2 and 50 characters). It is recommended to have a database for each of your application. The free tier is limited to 5 databases. keyspace It is a logical grouping of your tables. (Between 2 and 48 characters), Please use lower cases and snake_case . Cloud Provider Use the one you like, click a cloud provider logo, pick an Area in the list and finally pick a region. We recommend to pick one the closes to you to readuce latencies but in free tier very few difference. \u2139\ufe0f Create Database button becomes enabled only when all fields are filled properly. Please use only lower cases and no space for a keyspace name. \u2139\ufe0f You will see your new database pending in the Dashboard.The status will change to Active when the database is ready, this will only take 2-3 minutes. You will also receive an email when it is ready. \ud83d\udc41\ufe0f Walkthrough","title":"\u2705 Step 2: Complete the creation form"},{"location":"language-go/","text":"TODO package main import ( \"archive/zip\" \"context\" \"crypto/tls\" \"crypto/x509\" \"encoding/json\" \"fmt\" \"io\" \"io/ioutil\" \"os\" \"path/filepath\" \"strconv\" \"strings\" \"github.com/gocql/gocql\" ) type Config struct { Host string `json:\"host\"` Port int `json:\"cql_port\"` } func main () { var clientID = os . Getenv ( \"ASTRA_CLIENT_ID\" ) var clientSecret = os . Getenv ( \"ASTRA_CLIENT_SECRET\" ) var secureConnectBundle = os . Getenv ( \"SECURE_CONNECT_BUNDLE\" ) if clientID == \"\" || clientSecret == \"\" || secureConnectBundle == \"\" { panic ( \"missing required environment variables\" ) } secureBundleDir := os . TempDir () fmt . Printf ( \"extracting secure connect bundle [%s] to [%s]\\n\" , secureConnectBundle , secureBundleDir ) if err := Unzip ( secureConnectBundle , secureBundleDir ); err != nil { panic ( err ) } configPath , _ := filepath . Abs ( secureBundleDir + \"/config.json\" ) fmt . Println ( \"config: \" + configPath ) configData , _ := ioutil . ReadFile ( configPath ) var cfg Config json . Unmarshal ( configData , & cfg ) cluster := gocql . NewCluster ( cfg . Host ) cluster . Authenticator = gocql . PasswordAuthenticator { Username : clientID , Password : clientSecret , } host := cfg . Host + \":\" + strconv . Itoa ( cfg . Port ) cluster . Hosts = [] string { host } fmt . Println ( \"connecting to: \" + host ) certPath , _ := filepath . Abs ( secureBundleDir + \"/cert\" ) keyPath , _ := filepath . Abs ( secureBundleDir + \"/key\" ) caPath , _ := filepath . Abs ( secureBundleDir + \"/ca.crt\" ) cert , _ := tls . LoadX509KeyPair ( certPath , keyPath ) caCert , _ := ioutil . ReadFile ( caPath ) caCertPool := x509 . NewCertPool () caCertPool . AppendCertsFromPEM ( caCert ) cluster . SslOpts = & gocql . SslOptions { Config : & tls . Config { Certificates : [] tls . Certificate { cert }, ServerName : cfg . Host , RootCAs : caCertPool , }, } session , err := cluster . CreateSession () if err != nil { panic ( err ) } fmt . Printf ( \"session established: %v\\n\" , session ) var releaseVersion string if err := session . Query ( \"select release_version from system.local\" ). WithContext ( context . Background ()). Consistency ( gocql . One ). Scan ( & releaseVersion ); err != nil { panic ( err ) } fmt . Printf ( \"release version: %s\\n\" , releaseVersion ) } func Unzip ( src , dest string ) error { r , err := zip . OpenReader ( src ) if err != nil { return err } defer func () { if err := r . Close (); err != nil { panic ( err ) } }() os . MkdirAll ( dest , 0755 ) // Closure to address file descriptors issue with all the deferred .Close() methods extractAndWriteFile := func ( f * zip . File ) error { rc , err := f . Open () if err != nil { return err } defer func () { if err := rc . Close (); err != nil { panic ( err ) } }() path := filepath . Join ( dest , f . Name ) // Check for ZipSlip (Directory traversal) if ! strings . HasPrefix ( path , filepath . Clean ( dest ) + string ( os . PathSeparator )) { return fmt . Errorf ( \"illegal file path: %s\" , path ) } if f . FileInfo (). IsDir () { os . MkdirAll ( path , f . Mode ()) } else { os . MkdirAll ( filepath . Dir ( path ), f . Mode ()) f , err := os . OpenFile ( path , os . O_WRONLY | os . O_CREATE | os . O_TRUNC , f . Mode ()) if err != nil { return err } defer func () { if err := f . Close (); err != nil { panic ( err ) } }() _ , err = io . Copy ( f , rc ) if err != nil { return err } } return nil } for _ , f := range r . File { err := extractAndWriteFile ( f ) if err != nil { return err } } return nil }","title":"Language go"},{"location":"section-coding/","text":"Coding \u00b6","title":"Home"},{"location":"section-coding/#coding","text":"","title":"Coding"},{"location":"section-work-with-data/","text":"Work with Data \u00b6","title":"Home"},{"location":"section-work-with-data/#work-with-data","text":"","title":"Work with Data"}]}